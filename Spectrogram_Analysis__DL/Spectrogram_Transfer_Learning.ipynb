{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-henry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "casual-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- TEST USER ----------- #\n",
    "\n",
    "TEST_USER      = '007'\n",
    "\n",
    "BASE_DIR       = '../'\n",
    "IMG_DIR        = 'Spectrogram-Images/'\n",
    "LOG_DIR        = 'Logs/'\n",
    "\n",
    "USERS          = ['001', '002', '003', '004', '005', '006', '007']\n",
    "\n",
    "# ------------------------------- Only Dynalic Gestures ------------------------------ #\n",
    "GESTURES       = ['j', 'z', 'bad', 'deaf', 'fine', 'good', 'goodbye', 'hello', 'hungry',\n",
    "                  'me', 'no', 'please', 'sorry', 'thankyou', 'yes', 'you']\n",
    "AXES           = ['X', 'Y', 'Z']\n",
    "\n",
    "BATCH_SIZE     = 32\n",
    "IMG_LEN        = 160\n",
    "IMG_SIZE       = (IMG_LEN, IMG_LEN)\n",
    "\n",
    "# ------------- FOR THE GREATER GOOD :) ------------- #\n",
    "TRAIN_LEN      = 960\n",
    "TEST_LEN       = 160\n",
    "\n",
    "EPOCHS         = 15\n",
    "LEARNING_RATE  = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "different-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(axis):\n",
    "    X_train = np.zeros((TRAIN_LEN, IMG_LEN, IMG_LEN, 3))\n",
    "    X_test = np.zeros((TEST_LEN, IMG_LEN, IMG_LEN, 3))\n",
    "    y_train = np.zeros((TRAIN_LEN, 1))\n",
    "    y_test = np.zeros((TEST_LEN, 1))\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "        \n",
    "    for gesture in GESTURES:\n",
    "        print('loading data for the ' + gesture + ' gesture on the '  + axis + ' axis ... ', end='')\n",
    "        path = os.path.join(BASE_DIR, IMG_DIR, axis, gesture)\n",
    "        for filename in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(path, filename))\n",
    "            resized = cv2.resize(img, IMG_SIZE)\n",
    "            if filename[1:4] != TEST_USER:\n",
    "                X_train[train_count, :] = resized\n",
    "                y_train[train_count, 0] = GESTURES.index(gesture)\n",
    "                train_count = train_count + 1\n",
    "            else:\n",
    "                X_test[test_count, :] = resized\n",
    "                y_test[test_count, 0] = GESTURES.index(gesture)\n",
    "                test_count = test_count + 1\n",
    "                \n",
    "        print('√')\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-allah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for the j gesture on the X axis ... √\n",
      "loading data for the z gesture on the X axis ... √\n",
      "loading data for the bad gesture on the X axis ... √\n",
      "loading data for the deaf gesture on the X axis ... √\n",
      "loading data for the fine gesture on the X axis ... √\n",
      "loading data for the good gesture on the X axis ... √\n",
      "loading data for the goodbye gesture on the X axis ... √\n",
      "loading data for the hello gesture on the X axis ... √\n",
      "loading data for the hungry gesture on the X axis ... √\n",
      "loading data for the me gesture on the X axis ... √\n",
      "loading data for the no gesture on the X axis ... √\n",
      "loading data for the please gesture on the X axis ... √\n",
      "loading data for the sorry gesture on the X axis ... √\n",
      "loading data for the thankyou gesture on the X axis ... √\n",
      "loading data for the yes gesture on the X axis ... √\n",
      "loading data for the you gesture on the X axis ... √\n",
      "loading data for the j gesture on the Y axis ... √\n",
      "loading data for the z gesture on the Y axis ... √\n",
      "loading data for the bad gesture on the Y axis ... √\n",
      "loading data for the deaf gesture on the Y axis ... √\n",
      "loading data for the fine gesture on the Y axis ... √\n",
      "loading data for the good gesture on the Y axis ... √\n",
      "loading data for the goodbye gesture on the Y axis ... √\n",
      "loading data for the hello gesture on the Y axis ... √\n",
      "loading data for the hungry gesture on the Y axis ... √\n",
      "loading data for the me gesture on the Y axis ... √\n",
      "loading data for the no gesture on the Y axis ... √\n",
      "loading data for the please gesture on the Y axis ... √\n",
      "loading data for the sorry gesture on the Y axis ... √\n",
      "loading data for the thankyou gesture on the Y axis ... √\n",
      "loading data for the yes gesture on the Y axis ... √\n",
      "loading data for the you gesture on the Y axis ... √\n",
      "loading data for the j gesture on the Z axis ... √\n",
      "loading data for the z gesture on the Z axis ... √\n",
      "loading data for the bad gesture on the Z axis ... √\n",
      "loading data for the deaf gesture on the Z axis ... √\n",
      "loading data for the fine gesture on the Z axis ... √\n",
      "loading data for the good gesture on the Z axis ... √\n",
      "loading data for the goodbye gesture on the Z axis ... √\n",
      "loading data for the hello gesture on the Z axis ... √\n",
      "loading data for the hungry gesture on the Z axis ... √\n",
      "loading data for the me gesture on the Z axis ... √\n",
      "loading data for the no gesture on the Z axis ... √\n",
      "loading data for the please gesture on the Z axis ... √\n",
      "loading data for the sorry gesture on the Z axis ... √\n",
      "loading data for the thankyou gesture on the Z axis ... √\n",
      "loading data for the yes gesture on the Z axis ... √\n",
      "loading data for the you gesture on the Z axis ... √\n"
     ]
    }
   ],
   "source": [
    "X_train_x, X_test_x, y_train_x, y_test_x = load_data('X')\n",
    "X_train_y, X_test_y, y_train_y, y_test_y = load_data('Y')\n",
    "X_train_z, X_test_z, y_train_z, y_test_z = load_data('Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wireless-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "driven-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(len(GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coated-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30/30 [==============================] - 12s 339ms/step - loss: 3.1128 - accuracy: 0.0671\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 10s 333ms/step - loss: 2.5690 - accuracy: 0.1965\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 2.2808 - accuracy: 0.2584\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 2.0895 - accuracy: 0.3320\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 1.9454 - accuracy: 0.3508\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 1.8403 - accuracy: 0.3954\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 10s 337ms/step - loss: 1.7582 - accuracy: 0.4458\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 10s 339ms/step - loss: 1.6743 - accuracy: 0.4616\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 1.6334 - accuracy: 0.4873\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 1.4946 - accuracy: 0.5409\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 1.5032 - accuracy: 0.5204\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 10s 344ms/step - loss: 1.4607 - accuracy: 0.5458\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 1.3486 - accuracy: 0.5577\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 1.2903 - accuracy: 0.5898\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 10s 329ms/step - loss: 1.3086 - accuracy: 0.5982\n"
     ]
    }
   ],
   "source": [
    "model_x = get_model()\n",
    "history_x = model_x.fit(X_train_x, y_train_x, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.20      0.31        10\n",
      "         1.0       0.38      0.30      0.33        10\n",
      "         2.0       0.00      0.00      0.00        10\n",
      "         3.0       0.00      0.00      0.00        10\n",
      "         4.0       0.33      0.30      0.32        10\n",
      "         5.0       0.00      0.00      0.00        10\n",
      "         6.0       0.43      1.00      0.61        10\n",
      "         7.0       0.00      0.00      0.00        10\n",
      "         8.0       0.36      0.40      0.38        10\n",
      "         9.0       0.56      0.50      0.53        10\n",
      "        10.0       0.30      0.30      0.30        10\n",
      "        11.0       0.60      0.60      0.60        10\n",
      "        12.0       0.50      0.40      0.44        10\n",
      "        13.0       0.29      0.40      0.33        10\n",
      "        14.0       0.43      0.60      0.50        10\n",
      "        15.0       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.33      0.33      0.31       160\n",
      "weighted avg       0.33      0.33      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_x = tf.keras.Sequential([model_x, tf.keras.layers.Softmax()])\n",
    "y_pred_x = prob_x.predict(X_test_x)\n",
    "y_pred = np.argmax(y_pred_x, axis=1)\n",
    "print(classification_report(y_test_x.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "narrative-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30/30 [==============================] - 12s 332ms/step - loss: 2.3915 - accuracy: 0.2480\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 10s 330ms/step - loss: 2.0594 - accuracy: 0.3131\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 10s 333ms/step - loss: 1.8577 - accuracy: 0.3755\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 10s 337ms/step - loss: 1.7147 - accuracy: 0.4193\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 10s 330ms/step - loss: 1.6133 - accuracy: 0.4459\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 1.5197 - accuracy: 0.4939\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 10s 330ms/step - loss: 1.4627 - accuracy: 0.5179\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 1.3510 - accuracy: 0.5498\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 10s 328ms/step - loss: 1.3699 - accuracy: 0.5352\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 1.2750 - accuracy: 0.5712\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 10s 331ms/step - loss: 1.1820 - accuracy: 0.6194\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 1.1917 - accuracy: 0.6336\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 1.1339 - accuracy: 0.6538\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 1.0585 - accuracy: 0.6819\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 10s 328ms/step - loss: 1.0794 - accuracy: 0.6516\n"
     ]
    }
   ],
   "source": [
    "model_y = get_model()\n",
    "history_y = model_y.fit(X_train_y, y_train_y, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pressed-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.40      0.38        10\n",
      "         1.0       0.54      0.70      0.61        10\n",
      "         2.0       0.36      0.40      0.38        10\n",
      "         3.0       0.23      0.30      0.26        10\n",
      "         4.0       0.33      0.10      0.15        10\n",
      "         5.0       0.17      0.10      0.12        10\n",
      "         6.0       0.60      0.90      0.72        10\n",
      "         7.0       0.00      0.00      0.00        10\n",
      "         8.0       0.86      0.60      0.71        10\n",
      "         9.0       0.33      0.10      0.15        10\n",
      "        10.0       0.78      0.70      0.74        10\n",
      "        11.0       0.14      0.20      0.17        10\n",
      "        12.0       0.28      0.50      0.36        10\n",
      "        13.0       0.50      0.20      0.29        10\n",
      "        14.0       0.62      0.50      0.56        10\n",
      "        15.0       0.27      0.60      0.37        10\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.40      0.39      0.37       160\n",
      "weighted avg       0.40      0.39      0.37       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_y = tf.keras.Sequential([model_y, tf.keras.layers.Softmax()])\n",
    "y_pred_y = prob_y.predict(X_test_y)\n",
    "y_pred = np.argmax(y_pred_y, axis=1)\n",
    "print(classification_report(y_test_y.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "healthy-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30/30 [==============================] - 12s 335ms/step - loss: 2.6527 - accuracy: 0.2435\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 2.3114 - accuracy: 0.2650\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 10s 334ms/step - loss: 2.0002 - accuracy: 0.3605\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 10s 339ms/step - loss: 1.8013 - accuracy: 0.4114\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 10s 337ms/step - loss: 1.7304 - accuracy: 0.4395\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 10s 339ms/step - loss: 1.6073 - accuracy: 0.4745\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 1.4563 - accuracy: 0.5178\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 10s 344ms/step - loss: 1.4144 - accuracy: 0.5295\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 1.3586 - accuracy: 0.5366\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 10s 344ms/step - loss: 1.3134 - accuracy: 0.5603\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 1.2324 - accuracy: 0.5800\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 1.2289 - accuracy: 0.6078\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 1.1770 - accuracy: 0.6040\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 1.1298 - accuracy: 0.6224\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 10s 336ms/step - loss: 1.1211 - accuracy: 0.6349\n"
     ]
    }
   ],
   "source": [
    "model_z = get_model()\n",
    "history_z = model_z.fit(X_train_z, y_train_z, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coral-diploma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.10      0.15        10\n",
      "         1.0       0.40      0.60      0.48        10\n",
      "         2.0       0.19      0.30      0.23        10\n",
      "         3.0       0.45      0.50      0.48        10\n",
      "         4.0       0.25      0.10      0.14        10\n",
      "         5.0       0.25      0.10      0.14        10\n",
      "         6.0       0.59      1.00      0.74        10\n",
      "         7.0       0.23      0.30      0.26        10\n",
      "         8.0       0.88      0.70      0.78        10\n",
      "         9.0       0.50      0.40      0.44        10\n",
      "        10.0       0.60      0.30      0.40        10\n",
      "        11.0       0.00      0.00      0.00        10\n",
      "        12.0       0.50      0.50      0.50        10\n",
      "        13.0       0.44      0.40      0.42        10\n",
      "        14.0       0.59      1.00      0.74        10\n",
      "        15.0       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.44       160\n",
      "   macro avg       0.43      0.44      0.41       160\n",
      "weighted avg       0.43      0.44      0.41       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_z = tf.keras.Sequential([model_z, tf.keras.layers.Softmax()])\n",
    "y_pred_z = prob_z.predict(X_test_z)\n",
    "y_pred = np.argmax(y_pred_z, axis=1)\n",
    "print(classification_report(y_test_z.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesbian-canon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.20      0.31        10\n",
      "         1.0       0.62      0.80      0.70        10\n",
      "         2.0       0.33      0.40      0.36        10\n",
      "         3.0       0.50      0.60      0.55        10\n",
      "         4.0       1.00      0.70      0.82        10\n",
      "         5.0       0.25      0.10      0.14        10\n",
      "         6.0       0.62      1.00      0.77        10\n",
      "         7.0       0.12      0.10      0.11        10\n",
      "         8.0       0.75      0.90      0.82        10\n",
      "         9.0       1.00      0.80      0.89        10\n",
      "        10.0       0.80      0.40      0.53        10\n",
      "        11.0       0.17      0.10      0.12        10\n",
      "        12.0       0.43      0.60      0.50        10\n",
      "        13.0       0.57      0.80      0.67        10\n",
      "        14.0       0.56      1.00      0.71        10\n",
      "        15.0       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.57       160\n",
      "   macro avg       0.57      0.57      0.54       160\n",
      "weighted avg       0.57      0.57      0.54       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_total = y_pred_x * y_pred_y * y_pred_z\n",
    "y_pred = np.argmax(y_total, axis=1)\n",
    "report = classification_report(y_test_x.ravel(), y_pred, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '\\n\\nTEST_USER ' + TEST_USER + '\\n'\n",
    "underline = '=====================================\\n'\n",
    "log_dir = os.path.join(BASE_DIR, LOG_DIR)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "f = open(os.path.join(log_dir, 'spg_logs.txt'), 'a')\n",
    "f.write(config)\n",
    "f.write(underline)\n",
    "f.write(report)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "         \n",
    "         SPECTROGRAM TRANSFER LEARNING\n",
    "        \n",
    "            TEST USER       ACCURACY\n",
    "        ---------------------------------\n",
    "               001             54%\n",
    "               002             61%\n",
    "               003             63%\n",
    "               004             41%\n",
    "               005             48%\n",
    "               006             61%\n",
    "               007             57%\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
